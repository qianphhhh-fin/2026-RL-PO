import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cvxpy as cp
from stable_baselines3 import PPO
from env import PortfolioEnv
from dmpo_model import DMPOActionWrapper
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize


# --- è¾…åŠ©å‡½æ•°ï¼šè®¡ç®—é‡‘èæŒ‡æ ‡ ---
def calculate_metrics(returns):
    """è®¡ç®—ç´¯è®¡æ”¶ç›Š, å¤æ™®, æœ€å¤§å›æ’¤"""
    cum_ret = np.cumprod(1 + returns)
    total_ret = cum_ret[-1] - 1
    
    # å¹´åŒ–å¤æ™® (å‡è®¾252ä¸ªäº¤æ˜“æ—¥)
    mean = np.mean(returns)
    std = np.std(returns)
    if std == 0:
        sharpe = 0
    else:
        sharpe = (mean / std) * np.sqrt(252)
        
    # æœ€å¤§å›æ’¤
    running_max = np.maximum.accumulate(cum_ret)
    drawdown = (cum_ret - running_max) / running_max
    max_dd = np.min(drawdown)
    
    return total_ret, sharpe, max_dd, cum_ret

# --- åŸºå‡†ç­–ç•¥ 1: å‡å€¼æ–¹å·® (Mean-Variance) ---
def run_mean_variance(returns_history, lookback=30, max_turnover=0.10): # å¢åŠ å‚æ•°
    """
    ä¿®æ­£åçš„ MV ç­–ç•¥ï¼šå¢åŠ äº†ç¡¬æ¢æ‰‹ç‡çº¦æŸï¼Œå®ç°å…¬å¹³å¯¹æ¯”
    """
    n_steps, n_assets = returns_history.shape
    portfolio_returns = []
    
    # åˆå§‹æƒé‡
    weights = np.ones(n_assets) / n_assets
    
    for t in range(lookback, n_steps):
        window = returns_history[t-lookback:t]
        Sigma = np.cov(window.T)
        mu = np.mean(window, axis=0)
        
        # --- å¢åŠ çº¦æŸ ---
        w = cp.Variable(n_assets)
        w_prev = cp.Parameter(n_assets) # ä¸Šä¸€æœŸæƒé‡å‚æ•°
        w_prev.value = weights
        
        gamma = 0.5
        obj = cp.Maximize(mu @ w - gamma * cp.quad_form(w, Sigma))
        
        # è¿™é‡Œçš„çº¦æŸå¿…é¡»å’Œ DMPO å®Œå…¨ä¸€è‡´ï¼
        cons = [
            cp.sum(w) == 1, 
            w >= 0,
            cp.norm(w - w_prev, 1) <= max_turnover # <--- åŠ ä¸Šè¿™ä¸€è¡Œï¼
        ]
        
        prob = cp.Problem(obj, cons)
        
        try:
            # åŒæ ·æé«˜æ±‚è§£ç²¾åº¦
            prob.solve(solver=cp.OSQP, eps_abs=1e-6, eps_rel=1e-6)
            if w.value is not None:
                # ç®€å•çš„æ•°å€¼æ¸…æ´—
                new_w = np.maximum(w.value, 0)
                new_w /= np.sum(new_w)
                weights = new_w
        except:
            pass # æ±‚è§£å¤±è´¥åˆ™ä¸åŠ¨
            
        # è®¡ç®—æ”¶ç›Š (å«äº¤æ˜“æˆæœ¬ï¼Œä¸ºäº†å…¬å¹³)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç®€å•è®¡ç®—ï¼Œå®é™…åº”è¯¥å’Œ env é€»è¾‘ä¸€è‡´
        r = np.sum(weights * returns_history[t])
        # å¦‚æœä½ æƒ³ç®—å¾—æ›´ç»†ï¼Œå¯ä»¥æ‰£é™¤ costsï¼Œä½†ä½œä¸º baseline çº¯æ”¶ç›Šå¯¹æ¯”ä¹Ÿå¯ä»¥
        portfolio_returns.append(r)
        
    return np.array(portfolio_returns)


def main():
    print("ğŸ“Š åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ...")
    
    # 1. åˆ›å»ºåŸºç¡€ç¯å¢ƒ
    raw_env = PortfolioEnv(n_assets=10, lookback=30, max_turnover=0.10)
    # ä¿å­˜æ•°æ®ç”¨äº Benchmark
    obs, _ = raw_env.reset()
    market_returns_data = raw_env.returns 
    
    # 2. é‡æ–°æ„å»ºä¸è®­ç»ƒæ—¶ä¸€è‡´çš„ Wrapper æ ˆ
    def make_test_env():
        e = PortfolioEnv(n_assets=10, lookback=30, max_turnover=0.10)
        e = DMPOActionWrapper(e, max_turnover=0.10)
        # æ³¨å…¥ç›¸åŒæ•°æ®
        e.env.returns = market_returns_data 
        e.env.prices = raw_env.prices
        e.env.regimes = raw_env.regimes
        e.env.n_steps = len(market_returns_data)
        return e

    env = DummyVecEnv([make_test_env])
    
    # 3. âš¡ï¸ åŠ è½½ VecNormalize ç»Ÿè®¡æ•°æ® âš¡ï¸
    try:
        env = VecNormalize.load("./model/vec_normalize.pkl", env)
        env.training = False # æµ‹è¯•æ¨¡å¼ï¼šä¸æ›´æ–°å‡å€¼æ–¹å·®
        env.norm_reward = False # æµ‹è¯•æ¨¡å¼ï¼šæˆ‘ä»¬éœ€è¦çœŸå®çš„ Reward æ¥è¯„ä¼°
        print("âœ… æˆåŠŸåŠ è½½å½’ä¸€åŒ–å‚æ•°")
    except:
        print("âŒ æœªæ‰¾åˆ° vec_normalize.pklï¼Œç»“æœå°†ä¸å¯é ï¼")

    try:
        model = PPO.load("./model/dmpo_agent_fixed", env=env)
        print("âœ… æˆåŠŸåŠ è½½ DMPO æ¨¡å‹")
    except:
        print("âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
        return

    # --- è¿è¡Œ DMPO ---
    print("ğŸ¤– æ­£åœ¨è¿è¡Œ DMPO ç­–ç•¥...")
    dmpo_returns = []
    dmpo_violation_count = 0
    total_steps = 0
    
    obs = env.reset() # VecEnv è¿”å›çš„ obs å·²ç»æ˜¯å½’ä¸€åŒ–è¿‡çš„
    
    # VecEnv çš„ step å¾ªç¯ç•¥æœ‰ä¸åŒ
    for _ in range(len(market_returns_data) - 32): # å‡å» lookback
        action, _ = model.predict(obs, deterministic=True)
        obs, rewards, dones, infos = env.step(action)
        
        # VecEnv è¿”å›çš„ infos æ˜¯ä¸€ä¸ªåˆ—è¡¨
        info = infos[0]
        
        dmpo_returns.append(info['return'])
        
        # æé«˜å®¹å¿åº¦åˆ° 1e-4ï¼Œå› ä¸º solver ç²¾åº¦æ˜¯ 1e-6ï¼ŒPython æµ®ç‚¹ç´¯åŠ å¯èƒ½æœ‰è¯¯å·®
        if info['turnover'] > 0.10 + 1e-4:
            dmpo_violation_count += 1
        
        total_steps += 1
        if dones[0]: break

    # --- 4. è¿è¡ŒåŸºå‡†ç­–ç•¥ ---
    print("ğŸ“‰ æ­£åœ¨è¿è¡Œ Benchmark (1/N ç­‰æƒ)...")
    # 1/N ç­–ç•¥æ”¶ç›Š = æ¯æ—¥æ‰€æœ‰èµ„äº§æ”¶ç›Šçš„å¹³å‡å€¼
    # æ³¨æ„è¦å¯¹é½æ—¶é—´è½´ï¼šDMPO æ˜¯ä»ç¬¬30å¤©(lookback)å¼€å§‹äº¤æ˜“çš„
    bench_equal_returns = np.mean(market_returns_data[30:], axis=1)
    
    print("ğŸ“‰ æ­£åœ¨è¿è¡Œ Benchmark (Mean-Variance)...")
    bench_mv_returns = run_mean_variance(market_returns_data)
    # MV å¯èƒ½ä¼šå°‘å‡ å¤©æ•°æ®ï¼Œæˆªæ–­å¯¹é½
    min_len = min(len(dmpo_returns), len(bench_equal_returns), len(bench_mv_returns))
    
    dmpo_returns = np.array(dmpo_returns[:min_len])
    bench_equal_returns = bench_equal_returns[:min_len]
    bench_mv_returns = bench_mv_returns[:min_len]

    # --- 5. è®¡ç®—æŒ‡æ ‡ä¸å±•ç¤º ---
    metrics_dmpo = calculate_metrics(dmpo_returns)
    metrics_equal = calculate_metrics(bench_equal_returns)
    metrics_mv = calculate_metrics(bench_mv_returns)
    
    print("\n" + "="*60)
    print(f"{'Metric':<15} | {'DMPO (Ours)':<15} | {'1/N (Benchmark)':<15} | {'Mean-Var':<15}")
    print("-" * 60)
    print(f"{'Total Return':<15} | {metrics_dmpo[0]:>14.2%} | {metrics_equal[0]:>14.2%} | {metrics_mv[0]:>14.2%}")
    print(f"{'Sharpe Ratio':<15} | {metrics_dmpo[1]:>14.2f} | {metrics_equal[1]:>14.2f} | {metrics_mv[1]:>14.2f}")
    print(f"{'Max Drawdown':<15} | {metrics_dmpo[2]:>14.2%} | {metrics_equal[2]:>14.2%} | {metrics_mv[2]:>14.2%}")
    print("-" * 60)
    
    # ç¡¬çº¦æŸç»Ÿè®¡ (A/B æ ¼å¼)
    violation_rate = dmpo_violation_count / total_steps
    print(f"Hard Constraint Violations (Turnover > 10%):")
    print(f"ğŸ‘‰ {dmpo_violation_count}/{total_steps} ({violation_rate:.2%})")
    
    if dmpo_violation_count == 0:
        print("âœ… Validated: The differentiable layer successfully enforced strict constraints.")
    else:
        print("âš ï¸ Warning: Some constraints were violated.")

    # --- 6. ç»˜å›¾ ---
    plt.figure(figsize=(10, 6))
    plt.plot(metrics_dmpo[3], label='DMPO (RL + QP)', linewidth=2, color='red')
    plt.plot(metrics_equal[3], label='1/N Benchmark', linestyle='--', color='gray')
    plt.plot(metrics_mv[3], label='Mean-Variance', linestyle=':', color='blue')
    
    plt.title('Cumulative Returns Comparison')
    plt.xlabel('Trading Days')
    plt.ylabel('Portfolio Value')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig('./graph/backtest_result.png')
    print("\nğŸ“Š å‡€å€¼æ›²çº¿å·²ä¿å­˜ä¸º './graph/backtest_result.png'")
    plt.show()

if __name__ == "__main__":
    main()